#!/usr/bin/python3
''' update rules in suricata deployment
    cd /etc/suricata
    python3 ~/Dropbox/code/python/suricata_et_rule_update.py
  '''

import sys
import time
import gzip
import tarfile
import shutil
from os import path, listdir
from urllib import urlretrieve

def main():
  ''''''
  path_suricata = '/etc/suricata/'

  base_url       = 'https://rules.emergingthreats.net/open/suricata-1.3-enhanced/'
  rule_tar_name  = 'emerging.rules.tar.gz'
  rule_desc_name = 'SID-Descriptions-ETOpen.json.gz'
  rules_file = {'url': base_url+rule_tar_name,
                'path': path_suricata+rule_tar_name}
  desc_file  = {'url': base_url_old+rule_desc_name,
                'path': path_suricata+rule_desc_name}
  files = [rules_file, desc_file]

  download_files(files)
  extract_files(files)
  # move_files('/etc/suricata/etpro.rules/rules/', '/etc/suricata/rules/')
  # shutil.copy('/etc/suricata/rules/suricata-1.3-etpro.yaml', '/etc/suricata/suricata-1.3-etpro.yaml')

def download_files(file_list):
  ''' given list of files, download from url and save to path if file older than 6 hours '''
  print ' downloading files in list'
  for f in file_list:
    if path.exists(f['path']) and get_age(f['path']) < -21600:
      print ' ', f['path'], get_age(f['path'])
      print ' ', f['url'], 'to', f['path']
      urlretrieve(f['url'], f['path'], reporthook)
      print

    elif not path.exists(f['path']):
      print ' new file'
      urlretrieve(f['url'], f['path'], reporthook)
      print
    else:
      print '  skipping', f['path']
#
def reporthook(count, block_size, total_size):
  ''' show progress for urlretrieve '''
  global start_time
  if count == 0:
    start_time = time.time()
    return
  duration = time.time() - start_time
  progress_size = int(count * block_size)
  speed = int(progress_size / (1024 * duration))
  percent = int(count * block_size * 100 / total_size)
  sys.stdout.write("\r...%d%%, %d MB, %d KB/s, %d seconds passed" %
                  (percent, progress_size / (1024 * 1024), speed, duration))
  sys.stdout.flush()
#
def get_age(file_path):
  ''' given file path, return modified time delta '''
  if path.exists(file_path):
    now = time.time()
    file_mod_time = path.getmtime(file_path)
    return file_mod_time - now
  else:
    return False
#
def extract_files(files):
  ''' unzip and untar .tar.gz files '''
  print ' extracting'
  for packed_file in files:
    print ' ', packed_file['path']
    if packed_file['path'].endswith('gz'):
      packed_file['name'] = packed_file['path'].replace('.gz','')
      text = ''
      if packed_file['path'].endswith('.tar.gz'):
        packed_file['name'] = packed_file['name'].replace('.tar','')
        tar = tarfile.open(packed_file['path'], 'r:gz')
        tar.extractall(packed_file['name'])
        tar.close()
      else:
        text = unzip(packed_file['path'])
        if text:
          # print '  ', packed_file['path'].replace('.gz','').replace('.tar','')
          with open(packed_file['name'], 'w') as outfile:
            outfile.write(text)
#
def unzip(file_path):
  ''' read gzip file into a string '''
  with gzip.open(file_path, 'rb') as f:
    return f.read()
#
def move_files(src_dir, dst_dir):
  ''' move all files from src_dir to dst_dir '''
  print 'moving from', src_dir, 'to', dst_dir
  for source_file in listdir(src_dir):
    # print 
    shutil.move(path.join(src_dir, source_file), path.join(dst_dir, source_file))
  # shutil.rmtree(src_dir)
#
if __name__ == '__main__':
  main()
